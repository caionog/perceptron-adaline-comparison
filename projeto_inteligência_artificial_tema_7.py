# -*- coding: utf-8 -*-
"""PROJETO INTELIGÊNCIA ARTIFICIAL - TEMA 7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xILjnhl3QI7FdCwwG5uZ4qx-ve7EbuDG

## imports
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

"""## Váriáveis inicias"""

np.random.seed(42)

numeros_pontos = 500

#gera números(coordenadas dos pontos) aleatórios para a classe 0
# Aumentando a separação: centralizando classe 0 em (-3, -3)
x0 = np.random.randn(numeros_pontos,2) * 0.8 + np.array([-3, -3]) # Posição no gráfico
# gera 500 '-1' para mostrar a Classe 0
y0 = -np.ones(numeros_pontos)
# print(y0)

#gera números(coordenadas dos pontos) aleatórios para a classe 1
# Aumentando a separação: centralizando classe 1 em (3, 3)
x1 = np.random.randn(numeros_pontos,2) * 0.8 + np.array([3, 3]) # Posição no gráfico
# print(X0)

# gera 500 '1' para mostrar a Classe 1
y1 = np.ones(numeros_pontos)
# print(y0)

#juntar os arrays X0 e X1 verticalmente
X = np.vstack((x0,x1))
# print(X)

# junta os arrays y0 e y1 horizontalmente
Y = np.hstack((y0,y1))
print(Y)

# números de pontos de 0 a len(Y)
numeros= np.arange(len(Y))

np.random.shuffle(numeros)

X = X[numeros]
Y = Y[numeros]

print(X)

print(Y)

"""## Separação em treino e teste"""

# Divisão dos dados em 70% treino e 30% teste
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42, stratify=Y)

print(f"Dados de treino: {X_train.shape[0]} amostras")
print(f"Dados de teste: {X_test.shape[0]} amostras")

"""## Mostrar o dataset linearmente separável"""

plt.figure(figsize=(8, 6))
# Plotando a Classe -1
plt.scatter(X[Y == -1][:, 0], X[Y == -1][:, 1], color='black', label='Classe -1')
# Plotando a Classe 1
plt.scatter(X[Y == 1][:, 0], X[Y == 1][:, 1], color='red', label='Classe 1')

plt.title('Dataset')
plt.xlabel('Característica x')
plt.ylabel('Característica 2')
plt.legend()
plt.grid(True)
plt.show()

"""# Implementação do Perceptron"""

# #Função de ativação(discreta)
# # f(u) = { +1, se u >= 0; -1, se u < 0
def ativacao(u, limiar = 0):
  if u >= limiar:
    return 1
  else:
    return -1

# Função de treino do Perceptron (Regra de Aprendizado do Perceptron)
def treinarPerceptron(entradas, saidas, taxaAprendizado, epocas, imprimirErro = True):
    amostras, atributos = entradas.shape
    # Inicializa pesos e bias aleatoriamente com valores pequenos
    pesos = np.random.randn(atributos) * 0.01
    bias = np.random.randn() * 0.01
    
    listaErros = []
    historicoPesos = []

    # Percorre todas as épocas
    for epoca in range(epocas):
        erros = 0

        # Embaralha as amostras a cada época para melhor convergência
        indices = np.random.permutation(amostras)
        entradasEmbaralhadas = entradas[indices]
        saidasEmbaralhadas = saidas[indices]

        # Percorre por cada amostra
        for i, x in enumerate(entradasEmbaralhadas):
            # Saída do neurônio (combinação linear)
            u = np.dot(x, pesos) + bias
            # Aplica função de ativação (degrau)
            yPred = ativacao(u)

            # Atualiza pesos somente se houver erro de classificação
            if saidasEmbaralhadas[i] != yPred:
                # Calcula o fator de atualização
                atualiza = taxaAprendizado * (saidasEmbaralhadas[i] - yPred)
                # Atualiza pesos usando a regra do Perceptron
                # w = w + η * erro * x
                pesos += atualiza * x
                # Atualiza bias
                bias += atualiza
                erros += 1

        # Registra número de erros de classificação da época
        listaErros.append(erros)
        # Armazena uma cópia dos pesos (junta pesos e bias)
        historicoPesos.append(np.append(pesos.copy(), bias))

        if imprimirErro:
            print(f"Época {epoca + 1}: Pesos = {pesos}, Bias = {bias}")
            print(f"Época {epoca + 1} - Erros de Classificação: {erros}")

        # Opcional: parar se convergiu (sem erros)
        # if erros == 0:
        #     break

    return np.append(pesos, bias), historicoPesos, listaErros

"""# Funções de Avaliação"""

def predizerPerceptron(X, pesos_finais):
    """Função para fazer predições com o Perceptron treinado"""
    pesos = pesos_finais[:-1]  # Todos exceto o último (bias)
    bias = pesos_finais[-1]    # Último elemento é o bias
    
    predicoes = []
    for x in X:
        u = np.dot(x, pesos) + bias
        predicoes.append(ativacao(u))
    return np.array(predicoes)

def predizerAdaline(X, pesos_finais):
    """Função para fazer predições com o Adaline treinado"""
    pesos = pesos_finais[:-1]  # Todos exceto o último (bias)
    bias = pesos_finais[-1]    # Último elemento é o bias
    
    predicoes = []
    for x in X:
        u = np.dot(x, pesos) + bias
        # Para classificação, aplicamos um limiar na saída do Adaline
        predicoes.append(1 if u >= 0 else -1)
    return np.array(predicoes)

def calcularAcuracia(y_true, y_pred):
    """Calcula a acurácia das predições"""
    return np.mean(y_true == y_pred) * 100

def analisarConvergencia(listaErros, nome_modelo, taxa):
    """Analisa quando o modelo convergiu (estabilizou)"""
    # Considera convergido quando não há mudança significativa por 5 épocas consecutivas
    for i in range(5, len(listaErros)):
        if nome_modelo == "Perceptron":
            # Para Perceptron, converge quando erros = 0
            if all(erro == 0 for erro in listaErros[i-5:i]):
                print(f"{nome_modelo} (taxa {taxa}): Convergiu na época {i-4}")
                return i-4
        else:
            # Para Adaline, converge quando erro varia menos de 1%
            erros_recentes = listaErros[i-5:i]
            if len(set([round(e, 4) for e in erros_recentes])) <= 2:
                print(f"{nome_modelo} (taxa {taxa}): Convergiu na época {i-4}")
                return i-4
    
    print(f"{nome_modelo} (taxa {taxa}): Não convergiu em 50 épocas")
    return None

"""# Função para plotar a Reta a cada 5 épocas"""

def plotarRetaPorEpoca(historicoPesos, X, Y, taxa, modelo):
    for i, pesos in enumerate(historicoPesos):
        #Plota a cada 5 épocas ou na última
        if i % 5 == 0 or i == len(historicoPesos) - 1:
            # Intervalo para eixo x
            x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
            x_vals = np.linspace(x_min, x_max, 100)

            # Calcula a reta de decisão (y = (w1 * x + bias)/ w2)
            if pesos[1] != 0:
                y_vals = -(pesos[0] * x_vals + pesos[2]) / pesos[1]
            else:
                y_vals = np.zeros_like(x_vals)

            # Plota os pontos da reta
            plt.figure(figsize=(8, 6))
            plt.scatter(X[Y == -1][:, 0], X[Y == -1][:, 1], color="black", label="Classe -1")
            plt.scatter(X[Y == 1][:, 0], X[Y == 1][:, 1], color="red", label="Classe 1")
            plt.plot(x_vals, y_vals, color="blue", linestyle="--", label=f"Reta de Decisão (Época {i}")

            plt.title(f"{modelo} - Taxa de Aprendizado {taxa} - Época {i}")
            plt.xlabel("Característica 1")
            plt.ylabel("Característica 2")
            # Fixar escala para ter visualização consistente
            plt.xlim(-6, 6)
            plt.ylim(-6, 6)
            plt.legend()
            plt.grid(True)
            plt.show()

"""# Função para plotar a Reta Final com todas as épocas"""

def plotarRetaDecisaoFinal(historicoPesos, X, Y, taxa, modelo):
    # Pega os pesos da última época
    pesoFinal = historicoPesos[-1]

    # Gera Valores de x
    xMin, xMax = X[:, 0].min() - 1, X[:, 0].max() + 1
    xVals = np.linspace(xMin, xMax, 100)

    # Calcula os valores de y da reta com os pesos finais
    if pesoFinal[1] != 0:
        yVals = -(pesoFinal[0] * xVals + pesoFinal[2]) / pesoFinal[1]
    else:
        yVals = np.zeros_like(xVals)

    # Plota
    plt.figure(figsize=(8, 6))
    plt.scatter(X[Y == -1][:, 0], X[Y == -1][:, 1], color="black", label="Classe -1")
    plt.scatter(X[Y == 1][:, 0], X[Y == 1][:, 1], color="red", label="Classe 1")
    plt.plot(xVals, yVals, color="blue", linestyle="--", label="Reta de Decisão Final")

    plt.title(f"{modelo} - Reta de Decisão Final - Taxa de Aprendizado {taxa}")
    plt.xlabel("Característica 1")
    plt.ylabel("Característica 2")
    plt.legend()
    plt.grid(True)
    plt.show()

"""# Primeira taxa de aprendizado (0.0001) - Perceptron"""

print("=== TREINAMENTO PERCEPTRON - TAXA 0.0001 ===")
# Taxa de 0.0001
pesos1, historicoPesos1, listaErros1= treinarPerceptron(X_train, Y_train, 0.0001, 50)
plotarRetaPorEpoca(historicoPesos1, X_train, Y_train, taxa=0.0001, modelo='Perceptron')

# Avaliação
pred_train_p1 = predizerPerceptron(X_train, pesos1)
pred_test_p1 = predizerPerceptron(X_test, pesos1)
acuracia_train_p1 = calcularAcuracia(Y_train, pred_train_p1)
acuracia_test_p1 = calcularAcuracia(Y_test, pred_test_p1)

print(f"Acurácia no treino: {acuracia_train_p1:.2f}%")
print(f"Acurácia no teste: {acuracia_test_p1:.2f}%")
convergencia_p1 = analisarConvergencia(listaErros1, "Perceptron", 0.0001)

"""# Reta final - Perceptron - Taxa 0.0001"""

plotarRetaDecisaoFinal(historicoPesos1, X_train, Y_train, 0.0001, "Perceptron")

"""# Erros a cada 5 épocas - Perceptron - Taxa 0.0001"""

plt.plot(range(len(listaErros1)), listaErros1)
plt.xlabel("Época")
plt.ylabel("Erros de Classificação")
plt.title("Erro por Época - Perceptron (Taxa 0.0001)")
plt.grid(True)
plt.show()

"""# Segunda taxa de aprendizado (0.0005) - Perceptron"""

print("=== TREINAMENTO PERCEPTRON - TAXA 0.0005 ===")
# Taxa de 0.0005
pesos2, historicoPesos2, listaErros2= treinarPerceptron(X_train, Y_train, 0.0005, 50)
plotarRetaPorEpoca(historicoPesos2, X_train, Y_train, taxa=0.0005, modelo='Perceptron')

# Avaliação
pred_train_p2 = predizerPerceptron(X_train, pesos2)
pred_test_p2 = predizerPerceptron(X_test, pesos2)
acuracia_train_p2 = calcularAcuracia(Y_train, pred_train_p2)
acuracia_test_p2 = calcularAcuracia(Y_test, pred_test_p2)

print(f"Acurácia no treino: {acuracia_train_p2:.2f}%")
print(f"Acurácia no teste: {acuracia_test_p2:.2f}%")
convergencia_p2 = analisarConvergencia(listaErros2, "Perceptron", 0.0005)

"""# Reta Final - Perceptron - Taxa 0.0005"""

plotarRetaDecisaoFinal(historicoPesos2, X_train, Y_train, 0.0005, "Perceptron")

"""# Erros por época - Perceptron - Taxa 0.0005"""

plt.plot(range(len(listaErros2)), listaErros2)
plt.xlabel("Época")
plt.ylabel("Erros de Classificação")
plt.title("Erro por Época - Perceptron - (Taxa 0.0005)")
plt.grid(True)
plt.show()

"""# Implementação Adaline"""

# Função de ativação para Adaline (função identidade)
# A saída do neurônio Adaline é a combinação linear das entradas
def ativacaoAdaline(u):
  return u

# Função de treino do Adaline (Regra Delta)
def treinarAdaline(entradas, saidas, taxaAprendizado, epocas, imprimirErro = True):
    amostras, atributos = entradas.shape
    # Inicializa pesos e bias aleatoriamente
    pesos = np.random.uniform(low=-0.5, high=0.5, size=atributos)
    bias = np.random.uniform(low=-0.5, high=0.5)
    
    listaErros = []
    historicosPesos = []

    # Percorre todas as épocas
    for epoca in range(epocas):
        erroQuadraticoTotal = 0

        # Percorre por cada amostra
        for i in range(amostras):
            exemplo = entradas[i]
            esperado = saidas[i]

            # Saida do neurônio (combinação linear)
            u = np.dot(exemplo, pesos) + bias
            saida = ativacaoAdaline(u)

            # Cálculo do erro (erro = esperado - saida)
            erro = esperado - saida

            # Atualiza pesos usando a Regra Delta
            # w = w + taxaAprendizado * erro * xi
            pesos += taxaAprendizado * erro * exemplo
            bias += taxaAprendizado * erro

            # Calcula o erro quadrático para esta amostra
            erroQuadraticoTotal += erro**2

        # Calcula o erro médio quadrático da época
        erroMedioQuadratico = erroQuadraticoTotal / amostras
        listaErros.append(erroMedioQuadratico)
        # Armazena uma cópia dos pesos (junta pesos e bias)
        historicosPesos.append(np.append(pesos.copy(), bias))

        if imprimirErro:
            print(f"Época {epoca + 1} - Erro Médio Quadrático: {erroMedioQuadratico:.4f}")

    return np.append(pesos, bias), historicosPesos, listaErros

"""# Funções de Avaliação"""

def predizerPerceptron(X, pesos_finais):
    """Função para fazer predições com o Perceptron treinado"""
    pesos = pesos_finais[:-1]  # Todos exceto o último (bias)
    bias = pesos_finais[-1]    # Último elemento é o bias
    
    predicoes = []
    for x in X:
        u = np.dot(x, pesos) + bias
        predicoes.append(ativacao(u))
    return np.array(predicoes)

def predizerAdaline(X, pesos_finais):
    """Função para fazer predições com o Adaline treinado"""
    pesos = pesos_finais[:-1]  # Todos exceto o último (bias)
    bias = pesos_finais[-1]    # Último elemento é o bias
    
    predicoes = []
    for x in X:
        u = np.dot(x, pesos) + bias
        # Para classificação, aplicamos um limiar na saída do Adaline
        predicoes.append(1 if u >= 0 else -1)
    return np.array(predicoes)

def calcularAcuracia(y_true, y_pred):
    """Calcula a acurácia das predições"""
    return np.mean(y_true == y_pred) * 100

def analisarConvergencia(listaErros, nome_modelo, taxa):
    """Analisa quando o modelo convergiu (estabilizou)"""
    # Considera convergido quando não há mudança significativa por 5 épocas consecutivas
    for i in range(5, len(listaErros)):
        if nome_modelo == "Perceptron":
            # Para Perceptron, converge quando erros = 0
            if all(erro == 0 for erro in listaErros[i-5:i]):
                print(f"{nome_modelo} (taxa {taxa}): Convergiu na época {i-4}")
                return i-4
        else:
            # Para Adaline, converge quando erro varia menos de 1%
            erros_recentes = listaErros[i-5:i]
            if len(set([round(e, 4) for e in erros_recentes])) <= 2:
                print(f"{nome_modelo} (taxa {taxa}): Convergiu na época {i-4}")
                return i-4
    
    print(f"{nome_modelo} (taxa {taxa}): Não convergiu em 50 épocas")
    return None

"""# Primeira taxa de aprendizado (0.0001) - Adaline"""

print("=== TREINAMENTO ADALINE - TAXA 0.0001 ===")
# Taxa de 0.0001
pesosAdaline1, historicoPesosAdaline1, listaErrosAdaline1 = treinarAdaline(X_train, Y_train, 0.0001, 50)

# Avaliação
pred_train_a1 = predizerAdaline(X_train, pesosAdaline1)
pred_test_a1 = predizerAdaline(X_test, pesosAdaline1)
acuracia_train_a1 = calcularAcuracia(Y_train, pred_train_a1)
acuracia_test_a1 = calcularAcuracia(Y_test, pred_test_a1)

print(f"Acurácia no treino: {acuracia_train_a1:.2f}%")
print(f"Acurácia no teste: {acuracia_test_a1:.2f}%")
convergencia_a1 = analisarConvergencia(listaErrosAdaline1, "Adaline", 0.0001)

"""## Plotar por época - Adaline - Taxa 0.0001"""

plotarRetaPorEpoca(historicoPesosAdaline1, X_train, Y_train, taxa=0.0001, modelo='Adaline')

"""# Reta final - Adaline - Taxa 0.0001"""

plotarRetaDecisaoFinal(historicoPesosAdaline1, X_train, Y_train, 0.0001, "Adaline")

"""# Erros por época - Adaline - Taxa 0.0001"""

plt.plot(range(len(listaErrosAdaline1)), listaErrosAdaline1)
plt.xlabel("Época")
plt.ylabel("Erro Médio Quadrático")
plt.title("Erro por Época - Adaline (Taxa 0.0001)")
plt.grid(True)
plt.show()

"""# Segunda taxa de aprendizado (0.0005) - Adaline"""

print("=== TREINAMENTO ADALINE - TAXA 0.0005 ===")
# Taxa de 0.0005
pesosAdaline2, historicoPesosAdaline2, listaErrosAdaline2 = treinarAdaline(X_train, Y_train, 0.0005, 50)

# Avaliação
pred_train_a2 = predizerAdaline(X_train, pesosAdaline2)
pred_test_a2 = predizerAdaline(X_test, pesosAdaline2)
acuracia_train_a2 = calcularAcuracia(Y_train, pred_train_a2)
acuracia_test_a2 = calcularAcuracia(Y_test, pred_test_a2)

print(f"Acurácia no treino: {acuracia_train_a2:.2f}%")
print(f"Acurácia no teste: {acuracia_test_a2:.2f}%")
convergencia_a2 = analisarConvergencia(listaErrosAdaline2, "Adaline", 0.0005)

"""## Plotar por época - Adaline - Taxa 0.0005"""

plotarRetaPorEpoca(historicoPesosAdaline2, X_train, Y_train, taxa=0.0005, modelo='Adaline')

"""# Reta Final - Adaline - Taxa 0.0005"""

plotarRetaDecisaoFinal(historicoPesosAdaline2, X_train, Y_train, 0.0005, "Adaline")

"""# Erros por época - Adaline - Taxa 0.0005"""

plt.plot(range(len(listaErrosAdaline2)), listaErrosAdaline2)
plt.xlabel("Época")
plt.ylabel("Erro Médio Quadrático")
plt.title("Erro por Época - Adaline (Taxa 0.0005)")
plt.grid(True)
plt.show()

"""# Comparação Final e Análise dos Resultados"""

print("\n" + "="*60)
print("COMPARAÇÃO FINAL DOS MODELOS")
print("="*60)

print("\n--- PERCEPTRON ---")
print(f"Taxa 0.0001: Acurácia Teste = {acuracia_test_p1:.2f}%, Convergência = {convergencia_p1}")
print(f"Taxa 0.0005: Acurácia Teste = {acuracia_test_p2:.2f}%, Convergência = {convergencia_p2}")

print("\n--- ADALINE ---")
print(f"Taxa 0.0001: Acurácia Teste = {acuracia_test_a1:.2f}%, Convergência = {convergencia_a1}")
print(f"Taxa 0.0005: Acurácia Teste = {acuracia_test_a2:.2f}%, Convergência = {convergencia_a2}")

print("\n--- ANÁLISE DE SENSIBILIDADE À TAXA DE APRENDIZADO ---")
print("Perceptron:")
print(f"  - Taxa maior (0.0005): {'Converge mais rápido' if convergencia_p2 and convergencia_p1 and convergencia_p2 < convergencia_p1 else 'Pode ser instável'}")
print(f"  - Taxa menor (0.0001): {'Converge mais devagar mas de forma estável' if convergencia_p1 else 'Convergência lenta'}")

print("Adaline:")
print(f"  - Taxa maior (0.0005): {'Converge mais rápido' if convergencia_a2 and convergencia_a1 and convergencia_a2 < convergencia_a1 else 'Pode ser instável'}")
print(f"  - Taxa menor (0.0001): {'Converge mais devagar mas de forma estável' if convergencia_a1 else 'Convergência muito lenta'}")

# Plotar comparação dos erros
plt.figure(figsize=(15, 5))

plt.subplot(1, 3, 1)
plt.plot(range(len(listaErros1)), listaErros1, label='Taxa 0.0001', color='blue')
plt.plot(range(len(listaErros2)), listaErros2, label='Taxa 0.0005', color='red')
plt.xlabel("Época")
plt.ylabel("Erros de Classificação")
plt.title("Perceptron - Comparação de Taxas")
plt.legend()
plt.grid(True)

plt.subplot(1, 3, 2)
plt.plot(range(len(listaErrosAdaline1)), listaErrosAdaline1, label='Taxa 0.0001', color='green')
plt.plot(range(len(listaErrosAdaline2)), listaErrosAdaline2, label='Taxa 0.0005', color='orange')
plt.xlabel("Época")
plt.ylabel("Erro Médio Quadrático")
plt.title("Adaline - Comparação de Taxas")
plt.legend()
plt.grid(True)

plt.subplot(1, 3, 3)
acuracias = [acuracia_test_p1, acuracia_test_p2, acuracia_test_a1, acuracia_test_a2]
modelos = ['Perceptron\n(η=0.0001)', 'Perceptron\n(η=0.0005)', 'Adaline\n(η=0.0001)', 'Adaline\n(η=0.0005)']
cores = ['blue', 'red', 'green', 'orange']
plt.bar(modelos, acuracias, color=cores, alpha=0.7)
plt.ylabel("Acurácia no Teste (%)")
plt.ylim(0, 100)

for i, v in enumerate(acuracias):
    plt.text(i, v + 1, f'{v:.1f}%', ha='center', va='bottom')

plt.tight_layout()
plt.show()